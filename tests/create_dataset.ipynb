{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the src directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "# Now you can import the TimeSeriesDataset class\n",
    "from TimeSeriesDataset import TimeSeriesDataset as TSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dataset by downloading dataset or downloading the data from polity_url\n",
    "dataset = TSD(categories=['sc'])\n",
    "# download all datasets\n",
    "dataset.download_all_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polity gb_british_emp_2 (1900.0 - 1900.0) is inactive but has data for sc/polity-territories from 1800.0 to 1800.0\n",
      "Polity gb_british_emp_2 (1900.0 - 1900.0) is inactive but has data for sc/polity-territories_from from 1800.0 to 1800.0\n",
      "Polity gb_british_emp_2 (1900.0 - 1900.0) is inactive but has data for sc/polity-territories_to from 1800.0 to 1800.0\n",
      "Polity jp_ashikaga (1400.0 - 1400.0) is inactive but has data for sc/polity-populations from 1500.0 to 1500.0\n",
      "Polity us_early_illinois_confederation (1700.0 - 1700.0) is inactive but has data for sc/polity-populations from 1800.0 to 1800.0\n",
      "Polity jp_ashikaga (1400.0 - 1400.0) is inactive but has data for sc/polity-populations_from from 1500.0 to 1500.0\n",
      "Polity us_early_illinois_confederation (1700.0 - 1700.0) is inactive but has data for sc/polity-populations_from from 1800.0 to 1800.0\n",
      "Polity jp_ashikaga (1400.0 - 1400.0) is inactive but has data for sc/polity-populations_to from 1500.0 to 1500.0\n",
      "Polity us_early_illinois_confederation (1700.0 - 1700.0) is inactive but has data for sc/polity-populations_to from 1800.0 to 1800.0\n",
      "Polity jp_ashikaga (1400.0 - 1400.0) is inactive but has data for sc/population-of-the-largest-settlements from 1500.0 to 1500.0\n",
      "Polity gb_british_emp_2 (1900.0 - 1900.0) is inactive but has data for sc/population-of-the-largest-settlements from 1800.0 to 1800.0\n",
      "Polity it_roman_rep_2 (-200.0 - -200.0) is inactive but has data for sc/population-of-the-largest-settlements from -100.0 to -100.0\n",
      "Polity jp_ashikaga (1400.0 - 1400.0) is inactive but has data for sc/population-of-the-largest-settlements_from from 1500.0 to 1500.0\n",
      "Polity gb_british_emp_2 (1900.0 - 1900.0) is inactive but has data for sc/population-of-the-largest-settlements_from from 1800.0 to 1800.0\n",
      "Polity it_roman_rep_2 (-200.0 - -200.0) is inactive but has data for sc/population-of-the-largest-settlements_from from -100.0 to -100.0\n",
      "Polity jp_ashikaga (1400.0 - 1400.0) is inactive but has data for sc/population-of-the-largest-settlements_to from 1500.0 to 1500.0\n",
      "Polity gb_british_emp_2 (1900.0 - 1900.0) is inactive but has data for sc/population-of-the-largest-settlements_to from 1800.0 to 1800.0\n",
      "Polity it_roman_rep_2 (-200.0 - -200.0) is inactive but has data for sc/population-of-the-largest-settlements_to from -100.0 to -100.0\n",
      "-10000.0 1900.0\n",
      "-10000.0 1900.0\n",
      "-10000.0 1900.0\n"
     ]
    }
   ],
   "source": [
    "# clean up dataser and create a debug dataset dataset.debug\n",
    "dataset.debug_clean_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already cleaned\n"
     ]
    }
   ],
   "source": [
    "# if you try to debug the dataset twice it will inform you\n",
    "dataset.debug_clean_dataset()\n",
    "# save dataset\n",
    "dataset.save_dataset(path = \"../datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "NDFrame.infer_objects() got an unexpected keyword argument 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m dataset\u001b[38;5;241m.\u001b[39mremove_incomplete_rows(nan_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# build the social complexity variables\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_social_complexity\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# impute missing data\u001b[39;00m\n\u001b[1;32m     10\u001b[0m dataset\u001b[38;5;241m.\u001b[39mimpute_missing_values()\n",
      "File \u001b[0;32m~/Documents/repos/SeshatDatasetAnalysis/src/TimeSeriesDataset.py:304\u001b[0m, in \u001b[0;36mTimeSeriesDataset.build_social_complexity\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;66;03m# add hierarchy variables\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHierarchy\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: weighted_mean(row, social_complexity_mapping, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHierarchy\u001b[39m\u001b[38;5;124m\"\u001b[39m, imputation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mremove\u001b[39m\u001b[38;5;124m'\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 304\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGovernment\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweighted_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msocial_complexity_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGovernment\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimputation\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mzero\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInfrastructure\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: weighted_mean(row, social_complexity_mapping, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInfrastructure\u001b[39m\u001b[38;5;124m\"\u001b[39m, imputation\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzero\u001b[39m\u001b[38;5;124m'\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInformation\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: weighted_mean(row, social_complexity_mapping, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInformation\u001b[39m\u001b[38;5;124m\"\u001b[39m, imputation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzero\u001b[39m\u001b[38;5;124m'\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/repos/SeshatDatasetAnalysis/.venv/lib/python3.11/site-packages/pandas/core/frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9557\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9559\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m   9560\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   9561\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9566\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m   9567\u001b[0m )\n\u001b[0;32m-> 9568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/repos/SeshatDatasetAnalysis/.venv/lib/python3.11/site-packages/pandas/core/apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[0;32m--> 764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/repos/SeshatDatasetAnalysis/.venv/lib/python3.11/site-packages/pandas/core/apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 891\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/Documents/repos/SeshatDatasetAnalysis/.venv/lib/python3.11/site-packages/pandas/core/apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m    906\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 907\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    908\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    909\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    910\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    911\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/repos/SeshatDatasetAnalysis/src/TimeSeriesDataset.py:304\u001b[0m, in \u001b[0;36mTimeSeriesDataset.build_social_complexity.<locals>.<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;66;03m# add hierarchy variables\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHierarchy\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: weighted_mean(row, social_complexity_mapping, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHierarchy\u001b[39m\u001b[38;5;124m\"\u001b[39m, imputation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mremove\u001b[39m\u001b[38;5;124m'\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 304\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGovernment\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[43mweighted_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msocial_complexity_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGovernment\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimputation\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mzero\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInfrastructure\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: weighted_mean(row, social_complexity_mapping, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInfrastructure\u001b[39m\u001b[38;5;124m\"\u001b[39m, imputation\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzero\u001b[39m\u001b[38;5;124m'\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInformation\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: weighted_mean(row, social_complexity_mapping, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInformation\u001b[39m\u001b[38;5;124m\"\u001b[39m, imputation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzero\u001b[39m\u001b[38;5;124m'\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/repos/SeshatDatasetAnalysis/src/utils.py:82\u001b[0m, in \u001b[0;36mweighted_mean\u001b[0;34m(row, mappings, variable, category, imputation)\u001b[0m\n\u001b[1;32m     80\u001b[0m     entries \u001b[38;5;241m=\u001b[39m [entry \u001b[38;5;28;01mfor\u001b[39;00m entry, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(entries, values) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(value)]\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m imputation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzero\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 82\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     84\u001b[0m     entries \u001b[38;5;241m=\u001b[39m [entry \u001b[38;5;28;01mfor\u001b[39;00m entry, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(entries, values) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(value)]\n",
      "\u001b[0;31mTypeError\u001b[0m: NDFrame.infer_objects() got an unexpected keyword argument 'copy'"
     ]
    }
   ],
   "source": [
    "# import dataset\n",
    "dataset.load_dataset(path = \"../datasets\")\n",
    "\n",
    "\n",
    "# remove all rows that have less than 30% of the columns filled in\n",
    "dataset.remove_incomplete_rows(nan_threshold=0.3)\n",
    "# build the social complexity variables\n",
    "dataset.build_social_complexity()\n",
    "# impute missing data\n",
    "dataset.impute_missing_values()\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
